{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers torch PyMuPDF"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJh5BzsYQugz",
        "outputId": "61cfa1d8-7956-476b-fa35-8a13030dd009"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.41.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.0+cu121)\n",
            "Collecting PyMuPDF\n",
            "  Downloading PyMuPDF-1.24.4-cp310-none-manylinux2014_x86_64.whl (3.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.14.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m54.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting PyMuPDFb==1.24.3 (from PyMuPDF)\n",
            "  Downloading PyMuPDFb-1.24.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (15.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.8/15.8 MB\u001b[0m \u001b[31m73.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Installing collected packages: PyMuPDFb, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, PyMuPDF, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "Successfully installed PyMuPDF-1.24.4 PyMuPDFb-1.24.3 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "SYNQmzC5QrVD"
      },
      "outputs": [],
      "source": [
        "import fitz  # PyMuPDF\n",
        "from transformers import pipeline\n",
        "\n",
        "# Function to extract text from a PDF file\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    document = fitz.open(pdf_path)\n",
        "    text = ''\n",
        "    for page in document:\n",
        "        text += page.get_text()\n",
        "    document.close()\n",
        "    return text\n",
        "\n",
        "# Function to chunk text into manageable parts\n",
        "def chunk_text(text, chunk_size=1024):\n",
        "    # Split the text by whitespace to get words\n",
        "    words = text.split()\n",
        "    # Initialize chunks\n",
        "    chunks = []\n",
        "    current_chunk = []\n",
        "\n",
        "    # Create chunks of words based on the approximate character length\n",
        "    for word in words:\n",
        "        current_chunk.append(word)\n",
        "        if sum(len(w) + 1 for w in current_chunk) >= chunk_size:  # +1 for space\n",
        "            chunks.append(' '.join(current_chunk))\n",
        "            current_chunk = []\n",
        "\n",
        "    # Add the last chunk if any\n",
        "    if current_chunk:\n",
        "        chunks.append(' '.join(current_chunk))\n",
        "\n",
        "    return chunks\n",
        "\n",
        "from transformers import pipeline\n",
        "\n",
        "# Function to analyze text using a BERT model\n",
        "def analyze_text_with_bert(text_chunks):\n",
        "    # Load a BART model pipeline for summarization\n",
        "    summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
        "    summaries = []\n",
        "\n",
        "    # Summarize each chunk of text with a specified max_length\n",
        "    for chunk in text_chunks:\n",
        "        # Adjust max_length to be roughly half of the chunk length or a fixed value\n",
        "        max_length = min(len(chunk.split()), 88)  # or any other logic to set max_length\n",
        "        summary = summarizer(chunk, max_length=max_length)\n",
        "        summaries.append(summary[0]['summary_text'])\n",
        "\n",
        "    # Combine all summaries into one string\n",
        "    combined_summary = ' '.join(summaries)\n",
        "    return combined_summary\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Main execution block\n",
        "if __name__ == \"__main__\":\n",
        "    pdf_path = 'Test_Rep2.pdf'  # Path to the PDF file\n",
        "\n",
        "    # Extract text from the PDF\n",
        "    extracted_text = extract_text_from_pdf(pdf_path)\n",
        "\n",
        "    # Chunk the text for better processing\n",
        "    text_chunks = chunk_text(extracted_text, chunk_size=800)  # Adjust chunk size based on your observation\n",
        "\n",
        "    # Analyze text using BERT\n",
        "    insights = analyze_text_with_bert(text_chunks)\n",
        "\n",
        "    # Print the generated insights\n",
        "    print(\"Generated Insights:\")\n",
        "    print(insights)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "opmjRmk7Qxks",
        "outputId": "6b3731a9-34bc-428a-efde-b1dffe14d0f9"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Insights:\n",
            "To compare the performance of our LSTMs and DistilBERT models, we analyzed two different text representations: bag-of-words and sentiment analysis. For the Kaggle dataset, the model was not that accurate for any time period. For instance, “january” and “private” are strongly negatively correlated to stock price in the monthly case.  logistic regression performed surprisingly well on the API dataset with F1 scores of both labels above 0.65. We believe that the main difference is the shorter timespan. Since the dataset is restricted to tweets posted in a weeklong interval, current events will heavily affect both stock price and text information. It is important to note that in our analysis below, we do not train our model on 2024. For sentiment analysis, we used a pre-trained model from Hugging Face, twitter-roberta-base-sentiment-latest. Unlike the bag-of-words case, this method was not successful on any dataset or time period. We believe this is a result of the assignment of one label to an entire tweet. The Long Short-Term Memory (LSTM) neural network was used to predict Tesla stock price. The LSTM model demonstrated accuracies of around 50% across all labeling schemes. A notable aspect of the model's behavior was its significantly high recall, particularly in the weekly dataset. The performance on the curr_tweets dataset mirrored these trends, with the weekly model showing a high recall of 80.81%. This high recall indicates the model's strong ability to identify tweets that correlate with downward movements in Tesla's stock price. While this sensitivity to negative price movements is advantageous in risk management, it also led to a high rate of false positives. We used a training set of size 30,000 and validation of size 10,000. We performed our analysis after 5 epochs of fine-tuning. Overall, the results that we received from the DistilBERT were quite interesting, but still subpar to what we had hoped to achieve. With the quarterly model, our results were consistently the lowest across several different initialization points, with the validation and testing accuracy hovering right around ~50%. While these results were not exactly as we had hoped prior to our experimental analysis, it is interesting to see the difference between the confusion matrices of each of the different models. For example, within the weekly DistilBERT model, we see that despite having uniformly distributed labels,  weekly labeling might capture the immediate impact of such events and subsequently output “0” labels. quarterly labeling might smooth out these effects, which is why it would then show a much more evenly distributed confusion matrix with close precision and recall measures. have different impacts depending on the time frame.\n"
          ]
        }
      ]
    }
  ]
}